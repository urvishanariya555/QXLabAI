<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0,maximum-scale=1.0, user-scalable=no">
  <title>Qx Lab AI</title>
  <link rel="stylesheet" href="./style.css">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet"
      integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"
      integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
</head>

  <body data-spy="scroll" data-target="#scrollspy" data-offset="100">
    <nav class="navbar navbar-expand-lg custom-sticky-bar">
      <div class="container-fluid" style="padding: 0 24px;">
        <div class="header-logo">
          <a href="overView.html">QX LAB AI</a>
        </div>
        <button class="navbar-toggler ps-0 pe-0" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent"
          aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav me-auto mb-md-2 mb-lg-0">
            <li class="nav-item">
              <a class="nav-link active custom-res-text" aria-current="page" href="overView.html">Overview</a>
            </li>
            <li class="nav-item">
              <a class="nav-link d-res-none res-active" href="documentation.html">Documentation</a>
              <div class="accordion res-header-bar-list" id="accordionExample">
                <div class="accordion-item">
                  <h2 class="accordion-header" id="headingOne">
                    <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">
                      Documentation
                    </button>
                  </h2>
                  <div id="collapseOne" class="accordion-collapse collapse" aria-labelledby="headingOne" data-bs-parent="#accordionExample">
                    <div class="accordion-body">
                      <a href="documentation.html">
                        Introduction
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="quick-start.html">
                        Quickstart
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="libraries.html">
                        Libraries
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="models.html">
                        Models
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="deprecations.html">
                        Deprecations
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="tutorials.html">
                        Tutorials
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="policies.html">
                        Policies
                      </a>
                    </div>
                  </div>
                </div>
                <div class="accordion-item">
                  <h2 class="accordion-header" id="headingTwo">
                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
                      Guides
                    </button>
                  </h2>
                  <div id="collapseTwo" class="accordion-collapse collapse" aria-labelledby="headingTwo" data-bs-parent="#accordionExample">
                    <div class="accordion-body">
                      <a href="GPT-Models.html">
                        GPT
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="gpt-best-practices.html">
                        GPT best practices
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="image-generation.html">
                        Image generation
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="fine-tuning.html">
                        Fine-tuning
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="embeddings.html">
                        Embeddings
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="speech-to-text.html">
                        Speech to text
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="moderation.html">
                        moderation
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="rate-limits.html">
                        rate-limits
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="error-codes.html">
                        Error codes
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="safety-best-practices.html">
                        Safety best practices
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="production-best-practices.html">
                        Production best practices
                      </a>
                    </div>
                  </div>
                </div>
                <div class="accordion-item">
                  <h2 class="accordion-header" id="headingThree">
                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
                      Plugins
                    </button>
                  </h2>
                  <div id="collapseThree" class="accordion-collapse collapse" aria-labelledby="headingThree" data-bs-parent="#accordionExample">
                    <div class="accordion-body">
                      <a href="plugins-introduction.html">
                        Introduction
                      </a>
                    </div>
                    <div class="accordion-body">
                      <a href="plugins-getting-started.html">
                        Getting started
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="plugins-authentication.html">
                        Authentication
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="plugins-examples.html">
                        Examples
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="plugins-production.html">
                        Production
                      </a>
                      </div>
                    <div class="accordion-body">
                      <a href="plugins-review.html">
                        Plugin review
                      </a>
                    </div>
                  </div>
                </div>
                <div class="accordion-item">
                  <div class="accordion-header" >
                    <a href="api-reference.html" class="accordion-button collapsed pt-1 pb-1">
                      API reference
                    </a>
                  </div>
                </div>
                <div class="accordion-item">
                  <div class="accordion-header" >
                    <a href="examples.html" class="accordion-button collapsed pt-1 pb-1">
                      Examples
                    </a>
                  </div>
                </div>
                <div class="accordion-item">
                  <div class="accordion-header" >
                    <a class="accordion-button collapsed pt-1 pb-1">
                      Log in
                    </a>
                  </div>
                </div>
                <div class="accordion-item">
                  <div class="accordion-header" >
                    <a class="accordion-button collapsed pt-1 pb-1">
                      Sign up
                    </a>
                  </div>
                </div>
              </div>
            </li>
            <li class="nav-item">
              <a class="nav-link d-res-none" href="api-reference.html">API reference</a>
            </li>
            <li class="nav-item">
              <a class="nav-link d-res-none" href="examples.html">Examples</a>
            </li>
          </ul>
          <div class="res-flex">
            <button type="button" class="btn d-res-none">Log in</button>
            <button type="button" class="btn logInbtn d-res-none">Sign up</button>
          </div>
        </div>
      </div>
    </nav>
    <div class="d-flex">
      <div class="left-content-scroll">
        <div id="list-example" class="list-group border-radius-0">          
          <div id="scrollspy">
            <div class="sidebarPadding sidebarMainText">
              GET STARTED
            </div>
            <div>
              <a class="sidebarListText sidebarSubListText" href="documentation.html">
                <img src="./images/intro.svg" class="sidebarIcon"/>Introduction
              </a>
            </div>
            <div>
              <a class="sidebarListText sidebarSubListText" href="quick-start.html">
                <img src="./images/quickStarted.svg" class="sidebarIcon"/>Quickstart
              </a>
            </div>
            <div>
              <a class="sidebarListText sidebarSubListText" href="libraries.html">
                <img src="./images/Libraries.svg" class="sidebarIcon"/>Libraries
              </a>
            </div>
            <div>
              <a class="sidebarListText sidebarSubListText" href="models.html">
                <img src="./images/Models.svg" class="sidebarIcon"/>Models
              </a>
            </div>
            <a class="sidebarListText sidebarSubListText" href="deprecations.html">
              <img src="./images/Deprecations.svg" class="sidebarIcon"/>Deprecations
            </a>
            <a class="sidebarListText sidebarSubListText" href="tutorials.html">
              <img src="./images/Tutorials.svg" class="sidebarIcon"/>Tutorials
            </a>
            <a class="sidebarListText sidebarSubListText" href="policies.html">
              <img src="./images/Policies.svg" class="sidebarIcon"/>Policies
            </a>
          </div>
          <div class="sectionTopSection">
            <div class="sidebarPadding sidebarMainText">
              Guides
            </div>
            <div>
              <a class="sidebarListText sidebarSubListText" href="GPT-Models.html">
                <img src="./images/Gpt.svg" class="sidebarIcon"/>GPT
              </a>
            </div>
            <a class="sidebarListText sidebarSubListText" href="gpt-best-practices.html">
              <img src="./images/gptBestPractice.svg" class="sidebarIcon"/>GPT best practices
            </a>
            <div>
              <a class="sidebarListText sidebarSubListText" href="image-generation.html">
                <img src="./images/imagegeneration.svg" class="sidebarIcon"/>Image generation
              </a>
            </div>
            <div>
              <a class="sidebarListText sidebarSubListText" href="fine-tuning.html">
                <img src="./images/fineTuning.svg" class="sidebarIcon"/>Fine-tuning
              </a>
            </div>
            <div>
              <a class="sidebarListText list-group-item active" href="embeddings.html">
                <img src="./images/embedding.svg" class="sidebarIcon"/>Embeddings
              </a>
              <a class="list-group-item list-group-item-action sidebarSubListText tabSpace" 
              href="#list-item-1">
                Overview</a>
              <a class="list-group-item list-group-item-action sidebarSubListText tabSpace" 
              href="#list-item-2">
                Use Cases</a>
              <a class="list-group-item list-group-item-action sidebarSubListText tabSpace" 
              href="#list-item-3">
              Limitations & risks</a>              
            </div>
            <a class="sidebarListText sidebarSubListText" href="speech-to-text.html">
              <img src="./images/speechtotext.svg" class="sidebarIcon"/>Speech to text
            </a>
            <a class="sidebarListText sidebarSubListText" href="moderation.html">
              <img src="./images/moderation.svg" class="sidebarIcon"/>moderation
            </a>
            <a class="sidebarListText sidebarSubListText" href="rate-limits.html">
              <img src="./images/ratelimit.svg" class="sidebarIcon"/>rate-limits
            </a>
            <a class="sidebarListText sidebarSubListText" href="error-codes.html">
              <img src="./images/errorcode.svg" class="sidebarIcon"/>Error codes
            </a>
            <a class="sidebarListText sidebarSubListText" href="safety-best-practices.html">
              <img src="./images/Safety-best-practices.svg" class="sidebarIcon"/>Safety best practices
            </a>
            <a class="sidebarListText sidebarSubListText" href="production-best-practices.html">
              <img src="./images/Productionbest-practices.svg" class="sidebarIcon"/>Production best practices
            </a>
          </div>
          <div class="sectionTopSection">
            <div class="sidebarPadding sidebarMainText">
              Chat plugins
            </div>
            <a class="sidebarListText sidebarSubListText" href="plugins-introduction.html">
              <img src="./images/intro.svg" class="sidebarIcon"/>Introduction
            </a>
            <a class="sidebarListText sidebarSubListText" href="plugins-getting-started.html">
              <img src="./images/gettingStarted.svg" class="sidebarIcon"/>Getting started
            </a>
            <a class="sidebarListText sidebarSubListText" href="plugins-authentication.html">
              <img src="./images/Plugin-authentication.svg" class="sidebarIcon"/>Authentication
            </a>
            <a class="sidebarListText sidebarSubListText" href="plugins-examples.html">
              <img src="./images/example.svg" class="sidebarIcon"/>Examples
            </a>
            <a class="sidebarListText sidebarSubListText" href="plugins-production.html">
              <img src="./images/production.svg" class="sidebarIcon"/>Production
            </a>
            <a class="sidebarListText sidebarSubListText" href="plugins-review.html">
              <img src="./images/plugin_review.svg" class="sidebarIcon"/>Plugin review
            </a>
            <div class="sidebarListText">
              <img src="./images/Plugin_policies.svg" class="sidebarIcon"/>Plugin policies
            </div>
          </div>
        </div>
      </div>
      <div class="right-content-scroll custom-right-content">
        <div class="custom-right-content-width">
          <div data-bs-spy="scroll" data-bs-target="#list-example" data-bs-smooth-scroll="true"
            class="scrollspy-example pt-4" tabindex="0">
          <div class="markdown-page markdown-content docs-embeddings"><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/embeddings"><h1 class="anchor-heading" name="embeddings">Embeddings</h1></a></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/what-are-embeddings">
            <div id="list-item-1"></div>
            <h2 class="anchor-heading" name="what-are-embeddings">What are embeddings?</h2>
          </a></div><p>QX LabAI’s text embeddings measure the relatedness of text strings. Embeddings are commonly used for:</p><ul><li><strong>Search</strong> (where results are ranked by relevance to a query string)</li><li><strong>Clustering</strong> (where text strings are grouped by similarity)</li><li><strong>Recommendations</strong> (where items with related text strings are recommended)</li><li><strong>Anomaly detection</strong> (where outliers with little relatedness are identified)</li><li><strong>Diversity measurement</strong> (where similarity distributions are analyzed)</li><li><strong>Classification</strong> (where text strings are classified by their most similar label)</li></ul><p>An embedding is a vector (list) of floating point numbers. The <a href="/docs/guides/embeddings/which-distance-function-should-i-use">distance</a> between two vectors measures their relatedness. Small distances suggest high relatedness and large distances suggest low relatedness.</p><p>Visit our <a href="https://qxlabai.com/api/pricing/" target="_blank" rel="noopener noreferrer">pricing page</a> to learn about Embeddings pricing. Requests are billed based on the number of <a href="/tokenizer">tokens</a> in the <a href="/docs/api-reference/embeddings/create#embeddings/create-input">input</a> sent.</p><div class="notice notice-neutral has-body mt-2 mb-2"><div class="notice-message"><div class="notice-body"><div class="docs-samples-notice"><p><strong>To see embeddings in action, check out our code samples</strong></p><ul><li>Classification</li><li>Topic clustering</li><li>Search</li><li>Recommendations</li></ul><a tabindex="0" class="btn btn-sm btn-filled btn-primary" href="/docs/guides/embeddings/use-cases"><span class="btn-label-wrap"><span class="btn-label-inner">Browse Samples&zwj;</span></span></a></div></div></div></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/how-to-get-embeddings"><h2 class="anchor-heading" name="how-to-get-embeddings">How to get embeddings</h2></a></div><p>To get an embedding, send your text string to the <a href="/docs/api-reference/embeddings">embeddings API endpoint</a> along with a choice of embedding model ID (e.g., <code>text-embedding-ada-002</code>). The response will contain an embedding, which you can extract, save, and use.</p><p>Example requests:</p><div class="code-sample"><div class="code-sample-header"><div class="code-sample-title body-small">Example: Getting embeddings</div><div class="code-sample-select-wrap"><div class="code-sample-select-val">curl</div><select class="code-sample-select api-code-lang-select"><option disabled="" value="">Select library</option><option value="python">python</option><option value="curl">curl</option></select><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></div><div class="code-sample-copy"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span><span class="btn-label-inner">Copy&zwj;</span></span></button></div></div><div class="code-sample-body code-sample-body-small"><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-bash" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span></code><span class=""><span class="">curl https://api.qxlabai.com/v1/embeddings \
</span></span><span class=""><span class="">  -H </span><span class="hljs-string">"Content-Type: application/json"</span><span class=""> \
</span></span><span class=""><span class="">  -H </span><span class="hljs-string">"Authorization: Bearer </span><span class="hljs-string hljs-variable">$QX LabAI_API_KEY</span><span class="hljs-string">"</span><span class=""> \
</span></span><span class=""><span class="">  -d </span><span class="hljs-string">'{
</span></span><span class="hljs-string">    "input": "Your text string goes here",
</span><span class="hljs-string">    "model": "text-embedding-ada-002"
</span><span class="hljs-string">  }'</span></code></pre></div></div><p>Example response:</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-text" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span><span class="react-syntax-highlighter-line-number">9
</span><span class="react-syntax-highlighter-line-number">10
</span><span class="react-syntax-highlighter-line-number">11
</span><span class="react-syntax-highlighter-line-number">12
</span><span class="react-syntax-highlighter-line-number">13
</span><span class="react-syntax-highlighter-line-number">14
</span><span class="react-syntax-highlighter-line-number">15
</span><span class="react-syntax-highlighter-line-number">16
</span><span class="react-syntax-highlighter-line-number">17
</span><span class="react-syntax-highlighter-line-number">18
</span><span class="react-syntax-highlighter-line-number">19
</span><span class="react-syntax-highlighter-line-number">20
</span><span class="react-syntax-highlighter-line-number">21
</span></code><span class=""><span class="">{
</span></span><span class="">  "data": [
</span><span class="">    {
</span><span class="">      "embedding": [
</span><span class="">        -0.006929283495992422,
</span><span class="">        -0.005336422007530928,
</span><span class="">        ...
</span><span class="">        -4.547132266452536e-05,
</span><span class="">        -0.024047505110502243
</span><span class="">      ],
</span><span class="">      "index": 0,
</span><span class="">      "object": "embedding"
</span><span class="">    }
</span><span class="">  ],
</span><span class="">  "model": "text-embedding-ada-002",
</span><span class="">  "object": "list",
</span><span class="">  "usage": {
</span><span class="">    "prompt_tokens": 5,
</span><span class="">    "total_tokens": 5
</span><span class="">  }
</span><span class="">}</span></code></pre></div></div><p>See more Python code examples in the <a href="https://github.com/QX LabAI/QX LabAI-cookbook/" target="_blank" rel="noopener noreferrer">QX LabAI Cookbook</a>.</p><p>When using QX LabAI embeddings, please keep in mind their <a href="/docs/guides/embeddings/limitations-risks">limitations and risks</a>.</p><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/embedding-models"><h2 class="anchor-heading" name="embedding-models">Embedding models</h2></a></div><p>QX LabAI offers one second-generation embedding model (denoted by <code>-002</code> in the model ID) and 16 first-generation models (denoted by <code>-001</code> in the model ID).</p><p>We recommend using text-embedding-ada-002 for nearly all use cases. It’s better, cheaper, and simpler to use. Read the <a href="https://qxlabai.com/blog/new-and-improved-embedding-model" target="_blank" rel="noopener noreferrer">blog post announcement</a>.</p><div class="custom-table"><table><thead><tr><th>Model generation</th><th>tokenizer</th><th>max input tokens</th><th>knowledge cutoff</th></tr></thead><tbody><tr><td>V2</td><td>cl100k_base</td><td>8191</td><td>Sep 2021</td></tr><tr><td>V1</td><td>GPT-2/GPT-3</td><td>2046</td><td>Aug 2020</td></tr></tbody></table></div><p>Usage is priced per input token, at a rate of $0.0004 per 1000 tokens, or about ~3,000 pages per US dollar (assuming ~800 tokens per page):</p><div class="custom-table"><table><thead><tr><th>Model</th><th>Rough pages per dollar</th><th>Example performance on <a href="https://paperswithcode.com/sota/zero-shot-text-search-on-beir" target="_blank" rel="noopener noreferrer">BEIR</a> search eval</th></tr></thead><tbody><tr><td>text-embedding-ada-002</td><td>3000</td><td>53.9</td></tr><tr><td>*-davinci-*-001</td><td>6</td><td>52.8</td></tr><tr><td>*-curie-*-001</td><td>60</td><td>50.9</td></tr><tr><td>*-babbage-*-001</td><td>240</td><td>50.4</td></tr><tr><td>*-ada-*-001</td><td>300</td><td>49.0</td></tr></tbody></table></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/second-generation-models"><h3 class="anchor-heading" name="second-generation-models">Second-generation models</h3></a></div><div class="custom-table"><table><thead><tr><th>Model name</th><th>tokenizer</th><th>max input tokens</th><th>output dimensions</th></tr></thead><tbody><tr><td>text-embedding-ada-002</td><td>cl100k_base</td><td>8191</td><td>1536</td></tr></tbody></table></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-4"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">First-generation models (not recommended)</div></div><div class="expn-content hidden" id="expander-4"><p>All first-generation models (those ending in -001) use the <a href="https://platform.qxlabai.com/tokenizer" target="_blank" rel="noopener noreferrer">GPT-3 tokenizer</a> and have a max input of 2046 tokens.</p><p>First-generation embeddings are generated by five different model families tuned for three different tasks: text search, text similarity and code search. The search models come in pairs: one for short queries and one for long documents. Each family includes up to four models on a spectrum of quality and speed:</p><div class="custom-table"><table><thead><tr><th>Model</th><th>output dimensions</th></tr></thead><tbody><tr><td>Ada</td><td>1024</td></tr><tr><td>Babbage</td><td>2048</td></tr><tr><td>Curie</td><td>4096</td></tr><tr><td>Davinci</td><td>12288</td></tr></tbody></table></div><p>Davinci is the most capable, but is slower and more expensive than the other models. Ada is the least capable, but is significantly faster and cheaper.</p><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/similarity-embeddings"><h3 class="anchor-heading" name="similarity-embeddings">Similarity embeddings</h3></a></div><p>Similarity models are best at capturing semantic similarity between pieces of text.</p><div class="custom-table"><table><thead><tr><th>Use cases</th><th>Available models</th></tr></thead><tbody><tr><td>Clustering, regression, anomaly detection, visualization</td><td><code>text-similarity-ada-001</code><br><code>text-similarity-babbage-001</code><br><code>text-similarity-curie-001</code><br> <code>text-similarity-davinci-001</code></td></tr></tbody></table></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/text-search-embeddings"><h3 class="anchor-heading" name="text-search-embeddings">Text search embeddings</h3></a></div><p>Text search models help measure which long documents are most relevant to a short search query. Two models are used: one for embedding the search query and one for embedding the documents to be ranked. The document embeddings closest to the query embedding should be the most relevant.</p><div class="custom-table"><table><thead><tr><th>Use cases</th><th>Available models</th></tr></thead><tbody><tr><td>Search, context relevance, information retrieval</td><td><code>text-search-ada-doc-001</code><br><code>text-search-ada-query-001</code><br><code>text-search-babbage-doc-001</code><br><code>text-search-babbage-query-001</code><br><code>text-search-curie-doc-001</code><br><code>text-search-curie-query-001</code><br><code>text-search-davinci-doc-001</code><br><code>text-search-davinci-query-001</code></td></tr></tbody></table></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/code-search-embeddings"><h3 class="anchor-heading" name="code-search-embeddings">Code search embeddings</h3></a></div><p>Similarly to search embeddings, there are two types: one for embedding natural language search queries and one for embedding code snippets to be retrieved.</p><div class="custom-table"><table><thead><tr><th>Use cases</th><th>Available models</th></tr></thead><tbody><tr><td>Code search and relevance</td><td><code>code-search-ada-code-001</code><br><code>code-search-ada-text-001</code><br><code>code-search-babbage-code-001</code><br><code>code-search-babbage-text-001</code></td></tr></tbody></table></div><div class="mt-6 mb-6"><div class="notice notice-neutral has-body has-icon"><div class="notice-icon notice-icon-neutral"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M256 48C141.2 48 48 141.2 48 256s93.2 208 208 208 208-93.2 208-208S370.8 48 256 48zm21 312h-42V235h42v125zm0-166h-42v-42h42v42z"></path></svg></div><div class="notice-message"><div class="notice-body"><p>With the <code>-001</code> text embeddings (not <code>-002</code>, and not code embeddings), we suggest replacing newlines (<code>\n</code>) in your input with a single space, as we have seen worse results when newlines are present.</p></div></div></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/use-cases">
  <div id="list-item-2"></div>
  <h2 class="anchor-heading" name="use-cases">Use cases</h2>
</a></div><p>Here we show some representative use cases. We will use the <a href="https://www.kaggle.com/snap/amazon-fine-food-reviews" target="_blank" rel="noopener noreferrer">Amazon fine-food reviews dataset</a> for the following examples.</p><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/obtaining-the-embeddings"><h3 class="anchor-heading" name="obtaining-the-embeddings">Obtaining the embeddings</h3></a></div><p>The dataset contains a total of 568,454 food reviews Amazon users left up to October 2012. We will use a subset of 1,000 most recent reviews for illustration purposes. The reviews are in English and tend to be positive or negative. Each review has a ProductId, UserId, Score, review title (Summary) and review body (Text). For example:</p><div class=" custom-table" ><table><thead><tr><th>Product Id</th><th>User Id</th><th>Score</th><th>Summary</th><th>Text</th></tr></thead><tbody><tr><td>B001E4KFG0</td><td>A3SGXH7AUHU8GW</td><td>5</td><td>Good Quality Dog Food</td><td>I have bought several of the Vitality canned...</td></tr><tr><td>B00813GRG4</td><td>A1D87F6ZCVE5NK</td><td>1</td><td>Not as Advertised</td><td>Product arrived labeled as Jumbo Salted Peanut...</td></tr></tbody></table></div><p>We will combine the review summary and review text into a single combined text. The model will encode this combined text and output a single vector embedding.</p><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/Obtain_dataset.ipynb" target="_blank" rel="noreferrer" class="tag-link">Obtain_dataset.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span></code><span class=""><span class="hljs-function hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-function hljs-title">get_embedding</span><span class="hljs-function">(</span><span class="hljs-function hljs-params">text, model=</span><span class="hljs-function hljs-params hljs-string">"text-embedding-ada-002"</span><span class="hljs-function">):</span><span class="">
</span></span><span class=""><span class="">   text = text.replace(</span><span class="hljs-string">"\n"</span><span class="">, </span><span class="hljs-string">" "</span><span class="">)
</span></span><span class=""><span class="">   </span><span class="hljs-keyword">return</span><span class=""> QX LabAI.Embedding.create(</span><span class="hljs-built_in">input</span><span class=""> = [text], model=model)[</span><span class="hljs-string">'data'</span><span class="">][</span><span class="hljs-number">0</span><span class="">][</span><span class="hljs-string">'embedding'</span><span class="">]
</span></span><span class="">
</span><span class=""><span class="">df[</span><span class="hljs-string">'ada_embedding'</span><span class="">] = df.combined.apply(</span><span class="hljs-keyword">lambda</span><span class=""> x: get_embedding(x, model=</span><span class="hljs-string">'text-embedding-ada-002'</span><span class="">))
</span></span><span class=""><span class="">df.to_csv(</span><span class="hljs-string">'output/embedded_1k_reviews.csv'</span><span class="">, index=</span><span class="hljs-literal">False</span><span class="">)</span></span></code></pre></div></div><p>To load the data from a saved file, you can run the following:</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span></code><span class=""><span class="hljs-keyword">import</span><span class=""> pandas </span><span class="hljs-keyword">as</span><span class=""> pd
</span></span><span class="">
</span><span class=""><span class="">df = pd.read_csv(</span><span class="hljs-string">'output/embedded_1k_reviews.csv'</span><span class="">)
</span></span><span class=""><span class="">df[</span><span class="hljs-string">'ada_embedding'</span><span class="">] = df.ada_embedding.apply(</span><span class="hljs-built_in">eval</span><span class="">).apply(np.array)</span></span></code></pre></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-5"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Data visualization in 2D</div></div><div class="expn-content hidden" id="expander-5"><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/Visualizing_embeddings_in_2D.ipynb" target="_blank" rel="noreferrer" class="tag-link">Visualizing_embeddings_in_2D.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><p>The size of the embeddings varies with the complexity of the underlying model. In order to visualize this high dimensional data we use the t-SNE algorithm to transform the data into two dimensions.</p><p>We color the individual reviews based on the star rating which the reviewer has given:</p><ul><li>1-star: red</li><li>2-star: dark orange</li><li>3-star: gold</li><li>4-star: turquoise</li><li>5-star: dark green</li></ul><p>The visualization seems to have produced roughly 3 clusters, one of which has mostly negative reviews.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span><span class="react-syntax-highlighter-line-number">9
</span><span class="react-syntax-highlighter-line-number">10
</span><span class="react-syntax-highlighter-line-number">11
</span><span class="react-syntax-highlighter-line-number">12
</span><span class="react-syntax-highlighter-line-number">13
</span><span class="react-syntax-highlighter-line-number">14
</span><span class="react-syntax-highlighter-line-number">15
</span><span class="react-syntax-highlighter-line-number">16
</span><span class="react-syntax-highlighter-line-number">17
</span><span class="react-syntax-highlighter-line-number">18
</span><span class="react-syntax-highlighter-line-number">19
</span><span class="react-syntax-highlighter-line-number">20
</span></code><span class=""><span class="hljs-keyword">import</span><span class=""> pandas </span><span class="hljs-keyword">as</span><span class=""> pd
</span></span><span class=""><span class=""></span><span class="hljs-keyword">from</span><span class=""> sklearn.manifold </span><span class="hljs-keyword">import</span><span class=""> TSNE
</span></span><span class=""><span class=""></span><span class="hljs-keyword">import</span><span class=""> matplotlib.pyplot </span><span class="hljs-keyword">as</span><span class=""> plt
</span></span><span class=""><span class=""></span><span class="hljs-keyword">import</span><span class=""> matplotlib
</span></span><span class="">
</span><span class=""><span class="">df = pd.read_csv(</span><span class="hljs-string">'output/embedded_1k_reviews.csv'</span><span class="">)
</span></span><span class=""><span class="">matrix = df.ada_embedding.apply(</span><span class="hljs-built_in">eval</span><span class="">).to_list()
</span></span><span class="">
</span><span class=""><span class=""></span><span class="hljs-comment"># Create a t-SNE model and transform the data</span><span class="">
</span></span><span class=""><span class="">tsne = TSNE(n_components=</span><span class="hljs-number">2</span><span class="">, perplexity=</span><span class="hljs-number">15</span><span class="">, random_state=</span><span class="hljs-number">42</span><span class="">, init=</span><span class="hljs-string">'random'</span><span class="">, learning_rate=</span><span class="hljs-number">200</span><span class="">)
</span></span><span class="">vis_dims = tsne.fit_transform(matrix)
</span><span class="">
</span><span class=""><span class="">colors = [</span><span class="hljs-string">"red"</span><span class="">, </span><span class="hljs-string">"darkorange"</span><span class="">, </span><span class="hljs-string">"gold"</span><span class="">, </span><span class="hljs-string">"turquiose"</span><span class="">, </span><span class="hljs-string">"darkgreen"</span><span class="">]
</span></span><span class=""><span class="">x = [x </span><span class="hljs-keyword">for</span><span class=""> x,y </span><span class="hljs-keyword">in</span><span class=""> vis_dims]
</span></span><span class=""><span class="">y = [y </span><span class="hljs-keyword">for</span><span class=""> x,y </span><span class="hljs-keyword">in</span><span class=""> vis_dims]
</span></span><span class=""><span class="">color_indices = df.Score.values - </span><span class="hljs-number">1</span><span class="">
</span></span><span class="">
</span><span class="">colormap = matplotlib.colors.ListedColormap(colors)
</span><span class=""><span class="">plt.scatter(x, y, c=color_indices, cmap=colormap, alpha=</span><span class="hljs-number">0.3</span><span class="">)
</span></span><span class=""><span class="">plt.title(</span><span class="hljs-string">"Amazon ratings visualized in language using t-SNE"</span><span class="">)</span></span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-6"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Embedding as a text feature encoder for ML algorithms</div></div><div class="expn-content hidden" id="expander-6"><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/Regression_using_embeddings.ipynb" target="_blank" rel="noreferrer" class="tag-link">Regression_using_embeddings.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><p>An embedding can be used as a general free-text feature encoder within a machine learning model. Incorporating embeddings will improve the performance of any machine learning model, if some of the relevant inputs are free text. An embedding can also be used as a categorical feature encoder within a ML model. This adds most value if the names of categorical variables are meaningful and numerous, such as job titles. Similarity embeddings generally perform better than search embeddings for this task.</p><p>We observed that generally the embedding representation is very rich and information dense. For example, reducing the dimensionality of the inputs using SVD or PCA, even by 10%, generally results in worse downstream performance on specific tasks.</p><p>This code splits the data into a training set and a testing set, which will be used by the following two use cases, namely regression and classification.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span></code><span class=""><span class="hljs-keyword">from</span><span class=""> sklearn.model_selection </span><span class="hljs-keyword">import</span><span class=""> train_test_split
</span></span><span class="">
</span><span class="">X_train, X_test, y_train, y_test = train_test_split(
</span><span class=""><span class="">    </span><span class="hljs-built_in">list</span><span class="">(df.ada_embedding.values),
</span></span><span class="">    df.Score,
</span><span class=""><span class="">    test_size = </span><span class="hljs-number">0.2</span><span class="">,
</span></span><span class=""><span class="">    random_state=</span><span class="hljs-number">42</span><span class="">
</span></span><span class="">)</span></code></pre></div></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/regression-using-the-embedding-features"><h4 class="anchor-heading" name="regression-using-the-embedding-features">Regression using the embedding features</h4></a></div><p>Embeddings present an elegant way of predicting a numerical value. In this example we predict the reviewer’s star rating, based on the text of their review. Because the semantic information contained within embeddings is high, the prediction is decent even with very few reviews.</p><p>We assume the score is a continuous variable between 1 and 5, and allow the algorithm to predict any floating point value. The ML algorithm minimizes the distance of the predicted value to the true score, and achieves a mean absolute error of 0.39, which means that on average the prediction is off by less than half a star.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span></code><span class=""><span class="hljs-keyword">from</span><span class=""> sklearn.ensemble </span><span class="hljs-keyword">import</span><span class=""> RandomForestRegressor
</span></span><span class="">
</span><span class=""><span class="">rfr = RandomForestRegressor(n_estimators=</span><span class="hljs-number">100</span><span class="">)
</span></span><span class="">rfr.fit(X_train, y_train)
</span><span class="">preds = rfr.predict(X_test)</span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-7"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Classification using the embedding features</div></div><div class="expn-content hidden" id="expander-7"><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/Classification_using_embeddings.ipynb" target="_blank" rel="noreferrer" class="tag-link">Classification_using_embeddings.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><p>This time, instead of having the algorithm predict a value anywhere between 1 and 5, we will attempt to classify the exact number of stars for a review into 5 buckets, ranging from 1 to 5 stars.</p><p>After the training, the model learns to predict 1 and 5-star reviews much better than the more nuanced reviews (2-4 stars), likely due to more extreme sentiment expression.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span></code><span class=""><span class="hljs-keyword">from</span><span class=""> sklearn.ensemble </span><span class="hljs-keyword">import</span><span class=""> RandomForestClassifier
</span></span><span class=""><span class=""></span><span class="hljs-keyword">from</span><span class=""> sklearn.metrics </span><span class="hljs-keyword">import</span><span class=""> classification_report, accuracy_score
</span></span><span class="">
</span><span class=""><span class="">clf = RandomForestClassifier(n_estimators=</span><span class="hljs-number">100</span><span class="">)
</span></span><span class="">clf.fit(X_train, y_train)
</span><span class="">preds = clf.predict(X_test)</span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-8"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Zero-shot classification</div></div><div class="expn-content hidden" id="expander-8"><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/Zero-shot_classification_with_embeddings.ipynb" target="_blank" rel="noreferrer" class="tag-link">Zero-shot_classification_with_embeddings.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><p>We can use embeddings for zero shot classification without any labeled training data. For each class, we embed the class name or a short description of the class. To classify some new text in a zero-shot manner, we compare its embedding to all class embeddings and predict the class with the highest similarity.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span><span class="react-syntax-highlighter-line-number">9
</span><span class="react-syntax-highlighter-line-number">10
</span><span class="react-syntax-highlighter-line-number">11
</span><span class="react-syntax-highlighter-line-number">12
</span></code><span class=""><span class="hljs-keyword">from</span><span class=""> QX LabAI.embeddings_utils </span><span class="hljs-keyword">import</span><span class=""> cosine_similarity, get_embedding
</span></span><span class="">
</span><span class=""><span class="">df= df[df.Score!=</span><span class="hljs-number">3</span><span class="">]
</span></span><span class=""><span class="">df[</span><span class="hljs-string">'sentiment'</span><span class="">] = df.Score.replace({</span><span class="hljs-number">1</span><span class="">:</span><span class="hljs-string">'negative'</span><span class="">, </span><span class="hljs-number">2</span><span class="">:</span><span class="hljs-string">'negative'</span><span class="">, </span><span class="hljs-number">4</span><span class="">:</span><span class="hljs-string">'positive'</span><span class="">, </span><span class="hljs-number">5</span><span class="">:</span><span class="hljs-string">'positive'</span><span class="">})
</span></span><span class="">
</span><span class=""><span class="">labels = [</span><span class="hljs-string">'negative'</span><span class="">, </span><span class="hljs-string">'positive'</span><span class="">]
</span></span><span class=""><span class="">label_embeddings = [get_embedding(label, model=model) </span><span class="hljs-keyword">for</span><span class=""> label </span><span class="hljs-keyword">in</span><span class=""> labels]
</span></span><span class="">
</span><span class=""><span class=""></span><span class="hljs-function hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-function hljs-title">label_score</span><span class="hljs-function">(</span><span class="hljs-function hljs-params">review_embedding, label_embeddings</span><span class="hljs-function">):</span><span class="">
</span></span><span class=""><span class="">   </span><span class="hljs-keyword">return</span><span class=""> cosine_similarity(review_embedding, label_embeddings[</span><span class="hljs-number">1</span><span class="">]) - cosine_similarity(review_embedding, label_embeddings[</span><span class="hljs-number">0</span><span class="">])
</span></span><span class="">
</span><span class=""><span class="">prediction = </span><span class="hljs-string">'positive'</span><span class=""> </span><span class="hljs-keyword">if</span><span class=""> label_score(</span><span class="hljs-string">'Sample Review'</span><span class="">, label_embeddings) &gt; </span><span class="hljs-number">0</span><span class=""> </span><span class="hljs-keyword">else</span><span class=""> </span><span class="hljs-string">'negative'</span></span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-9"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Obtaining user and product embeddings for cold-start recommendation</div></div><div class="expn-content hidden" id="expander-9"><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/User_and_product_embeddings.ipynb" target="_blank" rel="noreferrer" class="tag-link">User_and_product_embeddings.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><p>We can obtain a user embedding by averaging over all of their reviews. Similarly, we can obtain a product embedding by averaging over all the reviews about that product. In order to showcase the usefulness of this approach we use a subset of 50k reviews to cover more reviews per user and per product.</p><p>We evaluate the usefulness of these embeddings on a separate test set, where we plot similarity of the user and product embedding as a function of the rating. Interestingly, based on this approach, even before the user receives the product we can predict better than random whether they would like the product.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><span class=""><span class="">user_embeddings = df.groupby(</span><span class="hljs-string">'UserId'</span><span class="">).ada_embedding.apply(np.mean)
</span></span><span class=""><span class="">prod_embeddings = df.groupby(</span><span class="hljs-string">'ProductId'</span><span class="">).ada_embedding.apply(np.mean)</span></span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-10"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Clustering</div></div><div class="expn-content hidden" id="expander-10"><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/Clustering.ipynb" target="_blank" rel="noreferrer" class="tag-link">Clustering.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><p>Clustering is one way of making sense of a large volume of textual data. Embeddings are useful for this task, as they provide semantically meaningful vector representations of each text. Thus, in an unsupervised way, clustering will uncover hidden groupings in our dataset.</p><p>In this example, we discover four distinct clusters: one focusing on dog food, one on negative reviews, and two on positive reviews.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span><span class="react-syntax-highlighter-line-number">9
</span></code><span class=""><span class="hljs-keyword">import</span><span class=""> numpy </span><span class="hljs-keyword">as</span><span class=""> np
</span></span><span class=""><span class=""></span><span class="hljs-keyword">from</span><span class=""> sklearn.cluster </span><span class="hljs-keyword">import</span><span class=""> KMeans
</span></span><span class="">
</span><span class="">matrix = np.vstack(df.ada_embedding.values)
</span><span class=""><span class="">n_clusters = </span><span class="hljs-number">4</span><span class="">
</span></span><span class="">
</span><span class=""><span class="">kmeans = KMeans(n_clusters = n_clusters, init=</span><span class="hljs-string">'k-means++'</span><span class="">, random_state=</span><span class="hljs-number">42</span><span class="">)
</span></span><span class="">kmeans.fit(matrix)
</span><span class=""><span class="">df[</span><span class="hljs-string">'Cluster'</span><span class="">] = kmeans.labels_</span></span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-11"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Text search using embeddings</div></div><div class="expn-content hidden" id="expander-11"><p>To retrieve the most relevant documents we use the cosine similarity between the embedding vectors of the query and each document, and return the highest scored documents.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span><span class="react-syntax-highlighter-line-number">9
</span></code><span class=""><span class="hljs-keyword">from</span><span class=""> QX LabAI.embeddings_utils </span><span class="hljs-keyword">import</span><span class=""> get_embedding, cosine_similarity
</span></span><span class="">
</span><span class=""><span class=""></span><span class="hljs-function hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-function hljs-title">search_reviews</span><span class="hljs-function">(</span><span class="hljs-function hljs-params">df, product_description, n=</span><span class="hljs-function hljs-params hljs-number">3</span><span class="hljs-function hljs-params">, pprint=</span><span class="hljs-function hljs-params hljs-literal">True</span><span class="hljs-function">):</span><span class="">
</span></span><span class=""><span class="">   embedding = get_embedding(product_description, model=</span><span class="hljs-string">'text-embedding-ada-002'</span><span class="">)
</span></span><span class=""><span class="">   df[</span><span class="hljs-string">'similarities'</span><span class="">] = df.ada_embedding.apply(</span><span class="hljs-keyword">lambda</span><span class=""> x: cosine_similarity(x, embedding))
</span></span><span class=""><span class="">   res = df.sort_values(</span><span class="hljs-string">'similarities'</span><span class="">, ascending=</span><span class="hljs-literal">False</span><span class="">).head(n)
</span></span><span class=""><span class="">   </span><span class="hljs-keyword">return</span><span class=""> res
</span></span><span class="">
</span><span class=""><span class="">res = search_reviews(df, </span><span class="hljs-string">'delicious beans'</span><span class="">, n=</span><span class="hljs-number">3</span><span class="">)</span></span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-12"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Code search using embeddings</div></div><div class="expn-content hidden" id="expander-12"><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/Code_search.ipynb" target="_blank" rel="noreferrer" class="tag-link">Code_search.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><p>Code search works similarly to embedding-based text search. We provide a method to extract Python functions from all the Python files in a given repository. Each function is then indexed by the <code>text-embedding-ada-002</code> model.</p><p>To perform a code search, we embed the query in natural language using the same model. Then we calculate cosine similarity between the resulting query embedding and each of the function embeddings. The highest cosine similarity results are most relevant.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span><span class="react-syntax-highlighter-line-number">9
</span><span class="react-syntax-highlighter-line-number">10
</span><span class="react-syntax-highlighter-line-number">11
</span></code><span class=""><span class="hljs-keyword">from</span><span class=""> QX LabAI.embeddings_utils </span><span class="hljs-keyword">import</span><span class=""> get_embedding, cosine_similarity
</span></span><span class="">
</span><span class=""><span class="">df[</span><span class="hljs-string">'code_embedding'</span><span class="">] = df[</span><span class="hljs-string">'code'</span><span class="">].apply(</span><span class="hljs-keyword">lambda</span><span class=""> x: get_embedding(x, model=</span><span class="hljs-string">'text-embedding-ada-002'</span><span class="">))
</span></span><span class="">
</span><span class=""><span class=""></span><span class="hljs-function hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-function hljs-title">search_functions</span><span class="hljs-function">(</span><span class="hljs-function hljs-params">df, code_query, n=</span><span class="hljs-function hljs-params hljs-number">3</span><span class="hljs-function hljs-params">, pprint=</span><span class="hljs-function hljs-params hljs-literal">True</span><span class="hljs-function hljs-params">, n_lines=</span><span class="hljs-function hljs-params hljs-number">7</span><span class="hljs-function">):</span><span class="">
</span></span><span class=""><span class="">   embedding = get_embedding(code_query, model=</span><span class="hljs-string">'text-embedding-ada-002'</span><span class="">)
</span></span><span class=""><span class="">   df[</span><span class="hljs-string">'similarities'</span><span class="">] = df.code_embedding.apply(</span><span class="hljs-keyword">lambda</span><span class=""> x: cosine_similarity(x, embedding))
</span></span><span class="">
</span><span class=""><span class="">   res = df.sort_values(</span><span class="hljs-string">'similarities'</span><span class="">, ascending=</span><span class="hljs-literal">False</span><span class="">).head(n)
</span></span><span class=""><span class="">   </span><span class="hljs-keyword">return</span><span class=""> res
</span></span><span class=""><span class="">res = search_functions(df, </span><span class="hljs-string">'Completions API tests'</span><span class="">, n=</span><span class="hljs-number">3</span><span class="">)</span></span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="expn"><div class="expn-title" role="button" aria-expanded="false" aria-controls="expander-13"><div class="expn-icon"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.646 1.646a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 0 .708l-6 6a.5.5 0 0 1-.708-.708L10.293 8 4.646 2.354a.5.5 0 0 1 0-.708z"></path></svg></div><div class="expn-label">Recommendations using embeddings</div></div><div class="expn-content hidden" id="expander-13"><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/Recommendation_using_embeddings.ipynb" target="_blank" rel="noreferrer" class="tag-link">Recommendation_using_embeddings.ipynb<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="tag-link-icon" width="1em" height="1em"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5859 5H11V3H17V9H15V6.4143L8.70718 12.7071L7.29297 11.2929L13.5859 5ZM9 5H5H3V7V15V17H5H13H15V15V11H13V15H5V7H9V5Z"></path></svg></a><p>Because shorter distances between embedding vectors represent greater similarity, embeddings can be useful for recommendation.</p><p>Below, we illustrate a basic recommender. It takes in a list of strings and one 'source' string, computes their embeddings, and then returns a ranking of the strings, ranked from most similar to least similar. As a concrete example, the linked notebook below applies a version of this function to the <a href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html" target="_blank" rel="noopener noreferrer">AG news dataset</a> (sampled down to 2,000 news article descriptions) to return the top 5 most similar articles to any given source article.</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span><span class="react-syntax-highlighter-line-number">9
</span><span class="react-syntax-highlighter-line-number">10
</span><span class="react-syntax-highlighter-line-number">11
</span><span class="react-syntax-highlighter-line-number">12
</span><span class="react-syntax-highlighter-line-number">13
</span><span class="react-syntax-highlighter-line-number">14
</span><span class="react-syntax-highlighter-line-number">15
</span><span class="react-syntax-highlighter-line-number">16
</span><span class="react-syntax-highlighter-line-number">17
</span><span class="react-syntax-highlighter-line-number">18
</span><span class="react-syntax-highlighter-line-number">19
</span></code><span class=""><span class="hljs-function hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-function hljs-title">recommendations_from_strings</span><span class="hljs-function">(</span><span class="hljs-function hljs-params">
</span></span><span class=""><span class="hljs-function hljs-params">   strings: </span><span class="hljs-function hljs-params hljs-type">List</span><span class="hljs-function hljs-params">[</span><span class="hljs-function hljs-params hljs-built_in">str</span><span class="hljs-function hljs-params">],
</span></span><span class=""><span class="hljs-function hljs-params">   index_of_source_string: </span><span class="hljs-function hljs-params hljs-built_in">int</span><span class="hljs-function hljs-params">,
</span></span><span class=""><span class="hljs-function hljs-params">   model=</span><span class="hljs-function hljs-params hljs-string">"text-embedding-ada-002"</span><span class="hljs-function hljs-params">,
</span></span><span class=""><span class="hljs-function hljs-params"></span><span class="hljs-function">) -&gt; </span><span class="hljs-function hljs-type">List</span><span class="hljs-function">[</span><span class="hljs-function hljs-built_in">int</span><span class="hljs-function">]:</span><span class="">
</span></span><span class=""><span class="">   </span><span class="hljs-string">"""Return nearest neighbors of a given string."""</span><span class="">
</span></span><span class="">
</span><span class=""><span class="">   </span><span class="hljs-comment"># get embeddings for all strings</span><span class="">
</span></span><span class=""><span class="">   embeddings = [embedding_from_string(string, model=model) </span><span class="hljs-keyword">for</span><span class=""> string </span><span class="hljs-keyword">in</span><span class=""> strings]
</span></span><span class="">
</span><span class=""><span class="">   </span><span class="hljs-comment"># get the embedding of the source string</span><span class="">
</span></span><span class="">   query_embedding = embeddings[index_of_source_string]
</span><span class="">
</span><span class=""><span class="">   </span><span class="hljs-comment"># get distances between the source embedding and other embeddings (function from embeddings_utils.py)</span><span class="">
</span></span><span class=""><span class="">   distances = distances_from_embeddings(query_embedding, embeddings, distance_metric=</span><span class="hljs-string">"cosine"</span><span class="">)
</span></span><span class="">
</span><span class=""><span class="">   </span><span class="hljs-comment"># get indices of nearest neighbors (function from embeddings_utils.py)</span><span class="">
</span></span><span class="">   indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)
</span><span class=""><span class="">   </span><span class="hljs-keyword">return</span><span class=""> indices_of_nearest_neighbors</span></span></code></pre></div></div><div class="expn-collapse"><button tabindex="0" class="btn btn-sm btn-filled btn-neutral" type="button"><span class="btn-label-wrap"><span class="btn-label-inner">Collapse&zwj;</span></span></button></div></div></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/limitations-risks">
  <div id="list-item-3"></div>
  <h2 class="anchor-heading" name="limitations-risks">Limitations &amp; risks</h2>

</a></div><p>Our embedding models may be unreliable or pose social risks in certain cases, and may cause harm in the absence of mitigations.</p><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/social-bias"><h4 class="anchor-heading" name="social-bias">Social bias</h4></a></div><blockquote><p><strong>Limitation</strong>: The models encode social biases, e.g. via stereotypes or negative sentiment towards certain groups.</p></blockquote><p>We found evidence of bias in our models via running the SEAT (<a href="https://arxiv.org/abs/1903.10561" target="_blank" rel="noopener noreferrer">May et al, 2019</a>) and the Winogender (<a href="https://arxiv.org/abs/1804.09301" target="_blank" rel="noopener noreferrer">Rudinger et al, 2018</a>) benchmarks. Together, these benchmarks consist of 7 tests that measure whether models contain implicit biases when applied to gendered names, regional names, and some stereotypes.</p><p>For example, we found that our models more strongly associate (a) European American names with positive sentiment, when compared to African American names, and (b) negative stereotypes with black women.</p><p>These benchmarks are limited in several ways: (a) they may not generalize to your particular use case, and (b) they only test for a very small slice of possible social bias.</p><p><strong>These tests are preliminary, and we recommend running tests for your specific use cases.</strong> These results should be taken as evidence of the existence of the phenomenon, not a definitive characterization of it for your use case. Please see our <a href="https://qxlabai.com/policies/usage-policies" target="_blank" rel="noopener noreferrer">usage policies</a> for more details and guidance.</p><p>Please <a href="https://help.qxlabai.com/en/" target="_blank" rel="noopener noreferrer">contact our support team via chat</a> if you have any questions; we are happy to advise on this.</p><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/blindness-to-recent-events"><h4 class="anchor-heading" name="blindness-to-recent-events">Blindness to recent events</h4></a></div><blockquote><p><strong>Limitation</strong>: Models lack knowledge of events that occurred after August 2020.</p></blockquote><p>Our models are trained on datasets that contain some information about real world events up until 8/2020. If you rely on the models representing recent events, then they may not perform well.</p><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/frequently-asked-questions"><h2 class="anchor-heading" name="frequently-asked-questions">Frequently asked questions</h2></a></div><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/how-can-i-tell-how-many-tokens-a-string-has-before-i-embed-it"><h3 class="anchor-heading" name="how-can-i-tell-how-many-tokens-a-string-has-before-i-embed-it">How can I tell how many tokens a string has before I embed it?</h3></a></div><p>In Python, you can split a string into tokens with QX LabAI's tokenizer <a href="https://github.com/QX LabAI/tiktoken" target="_blank" rel="noopener noreferrer"><code>tiktoken</code></a>.</p><p>Example code:</p><div class="code-sample"><div class="code-sample-body code-sample-body-large"><button tabindex="0" class="btn btn-sm btn-minimal btn-neutral code-sample-copy-float copy-btn-top " type="button" aria-label="Copy"><span class="btn-label-wrap"><span class="btn-node"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></span></span></button><pre class="hljs syntax-highlighter dark code-sample-pre"><code class="language-python" style="white-space: pre;"><code><span class="react-syntax-highlighter-line-number">1
</span><span class="react-syntax-highlighter-line-number">2
</span><span class="react-syntax-highlighter-line-number">3
</span><span class="react-syntax-highlighter-line-number">4
</span><span class="react-syntax-highlighter-line-number">5
</span><span class="react-syntax-highlighter-line-number">6
</span><span class="react-syntax-highlighter-line-number">7
</span><span class="react-syntax-highlighter-line-number">8
</span><span class="react-syntax-highlighter-line-number">9
</span></code><span class=""><span class="hljs-keyword">import</span><span class=""> tiktoken
</span></span><span class="">
</span><span class=""><span class=""></span><span class="hljs-function hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-function hljs-title">num_tokens_from_string</span><span class="hljs-function">(</span><span class="hljs-function hljs-params">string: </span><span class="hljs-function hljs-params hljs-built_in">str</span><span class="hljs-function hljs-params">, encoding_name: </span><span class="hljs-function hljs-params hljs-built_in">str</span><span class="hljs-function">) -&gt; </span><span class="hljs-function hljs-built_in">int</span><span class="hljs-function">:</span><span class="">
</span></span><span class=""><span class="">    </span><span class="hljs-string">"""Returns the number of tokens in a text string."""</span><span class="">
</span></span><span class="">    encoding = tiktoken.get_encoding(encoding_name)
</span><span class=""><span class="">    num_tokens = </span><span class="hljs-built_in">len</span><span class="">(encoding.encode(string))
</span></span><span class=""><span class="">    </span><span class="hljs-keyword">return</span><span class=""> num_tokens
</span></span><span class="">
</span><span class=""><span class="">num_tokens_from_string(</span><span class="hljs-string">"tiktoken is great!"</span><span class="">, </span><span class="hljs-string">"cl100k_base"</span><span class="">)</span></span></code></pre></div></div><p>For second-generation embedding models like <code>text-embedding-ada-002</code>, use the <code>cl100k_base</code> encoding.</p><p>More details and example code are in the QX LabAI Cookbook guide <a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb" target="_blank" rel="noopener noreferrer">how to count tokens with tiktoken</a>.</p><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/how-can-i-retrieve-k-nearest-embedding-vectors-quickly"><h3 class="anchor-heading" name="how-can-i-retrieve-k-nearest-embedding-vectors-quickly">How can I retrieve K nearest embedding vectors quickly?</h3></a></div><p>For searching over many vectors quickly, we recommend using a vector database. You can find examples of working with vector databases and the QX LabAI API <a href="https://github.com/QX LabAI/QX LabAI-cookbook/tree/main/examples/vector_databases" target="_blank" rel="noopener noreferrer">in our Cookbook</a> on GitHub.</p><p>Vector database options include:</p><ul><li><a href="https://github.com/chroma-core/chroma" target="_blank" rel="noopener noreferrer">Chroma</a>, an open-source embeddings store</li><li><a href="https://github.com/QX LabAI/QX LabAI-cookbook/blob/main/examples/vector_databases/Using_vector_databases_for_embeddings_search.ipynb" target="_blank" rel="noopener noreferrer">Milvus</a>, a vector database built for scalable similarity search</li><li><a href="https://github.com/QX LabAI/QX LabAI-cookbook/tree/main/examples/vector_databases/pinecone" target="_blank" rel="noopener noreferrer">Pinecone</a>, a fully managed vector database</li><li><a href="https://github.com/QX LabAI/QX LabAI-cookbook/tree/main/examples/vector_databases/qdrant" target="_blank" rel="noopener noreferrer">Qdrant</a>, a vector search engine</li><li><a href="https://github.com/QX LabAI/QX LabAI-cookbook/tree/main/examples/vector_databases/redis" target="_blank" rel="noopener noreferrer">Redis</a> as a vector database</li><li><a href="https://typesense.org/docs/0.24.0/api/vector-search.html" target="_blank" rel="noopener noreferrer">Typesense</a>, fast open source vector search</li><li><a href="https://github.com/QX LabAI/QX LabAI-cookbook/tree/main/examples/vector_databases/weaviate" target="_blank" rel="noopener noreferrer">Weaviate</a>, an open-source vector search engine</li><li><a href="https://github.com/QX LabAI/QX LabAI-cookbook/tree/main/examples/vector_databases/zilliz" target="_blank" rel="noopener noreferrer">Zilliz</a>, data infrastructure, powered by Milvus</li></ul><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/which-distance-function-should-i-use"><h3 class="anchor-heading" name="which-distance-function-should-i-use">Which distance function should I use?</h3></a></div><p>We recommend <a href="https://en.wikipedia.org/wiki/Cosine_similarity" target="_blank" rel="noopener noreferrer">cosine similarity</a>. The choice of distance function typically doesn’t matter much.</p><p>QX LabAI embeddings are normalized to length 1, which means that:</p><ul><li>Cosine similarity can be computed slightly faster using just a dot product</li><li>Cosine similarity and Euclidean distance will result in the identical rankings</li></ul><div class="anchor-heading-root"><a class="anchor-heading-link" href="/docs/guides/embeddings/can-i-share-my-embeddings-online"><h3 class="anchor-heading" name="can-i-share-my-embeddings-online">Can I share my embeddings online?</h3></a></div><p>Customers own their input and output from our models, including in the case of embeddings. You are responsible for ensuring that the content you input to our API does not violate any applicable law or our <a href="https://qxlabai.com/policies/terms-of-use" target="_blank" rel="noopener noreferrer">Terms of Use</a>.</p></div>
          </div>
        </div>
      </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm"
      crossorigin="anonymous"></script>
  </body>

</html>